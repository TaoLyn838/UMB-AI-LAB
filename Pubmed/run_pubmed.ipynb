{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc7e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.insert(0, '/home/chengtao/Workspace/pygcn')\n",
    "from torchdiffeq import odeint\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from pygcn.layers import GraphConvolution\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygcn.utils import load_data, encode_onehot, normalize, sparse_mx_to_torch_sparse_tensor, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763db35",
   "metadata": {},
   "source": [
    "## Model + Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a4435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adj(adj):\n",
    "    \"\"\"Ĩ = D^{-1/2}(A+I)D^{-1/2}\"\"\"\n",
    "    adj = adj + sp.eye(adj.shape[0])\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt)\n",
    "\n",
    "def row_normalize(features):\n",
    "    rowsum = np.array(features.sum(1))\n",
    "    r_inv = np.power(rowsum, -1.).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    return r_mat_inv.dot(features)\n",
    "\n",
    "def parse_index_file(filename):\n",
    "    \"\"\"Parse index file.\"\"\"\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "def labels_to_tensor(labels):\n",
    "    \"\"\"Convert labels to tensor.\"\"\"\n",
    "    labels_int = np.argmax(labels, axis=1)      # shape (N,)\n",
    "    labels_tensor = torch.LongTensor(labels_int)  # also shape (N,)\n",
    "    rows, cols = np.where(labels)                 # rows: node indices, cols: class indices\n",
    "    class_indices  = np.full(labels.shape[0], -1, int)\n",
    "    class_indices[rows] = cols                       # only labeled rows get 0…C–1, rest stay -1\n",
    "    labels_tensor   = torch.LongTensor(class_indices)  # shape (N,)\n",
    "    return labels_tensor\n",
    "\n",
    "def scipy_to_tensor(x):\n",
    "    dense = x.toarray()\n",
    "    features_tensor = torch.from_numpy(dense)\n",
    "    return features_tensor.float()\n",
    "\n",
    "def check_zero_row_indices(labels, idx_train, idx_val, idx_test):\n",
    "    \"\"\"Check if there are any zero row indices in the labels.\"\"\"\n",
    "    zero_row_indices = np.where(~labels.any(axis=1))[0]\n",
    "    if len(zero_row_indices) > 0:\n",
    "        print(\"Zero row indices found in labels:\", zero_row_indices)\n",
    "    else:\n",
    "        print(\"No zero row indices found in labels.\")\n",
    "    # Check if any of the zero row indices are in the train, val, or test sets\n",
    "    train_idx_set = set(idx_train.tolist())\n",
    "    val_idx_set = set(idx_val.tolist())\n",
    "    test_idx_set = set(idx_test.tolist())\n",
    "\n",
    "    if len(train_idx_set.intersection(zero_row_indices)) > 0:\n",
    "        return f\"Train set contains zero row indices, which they are {train_idx_set.intersection(zero_row_indices)}\"\n",
    "    if len(val_idx_set.intersection(zero_row_indices)) > 0:\n",
    "        return f\"Validation set contains zero row indices, which they are {val_idx_set.intersection(zero_row_indices)}\"\n",
    "    if len(test_idx_set.intersection(zero_row_indices)) > 0:\n",
    "        return f\"Test set contains zero row indices, which they are {test_idx_set.intersection(zero_row_indices)}\"\n",
    "    \n",
    "    return \"No zero row indices found in train, val, or test sets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9ff1512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0, verbose=False, trace_func=print, save_path='checkpoint.pth'):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.trace_func = trace_func\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        torch.save(model.state_dict(), self.save_path)\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.best_score:.6f} --> {-val_loss:.6f}).  Saving model ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, bias=True):\n",
    "        super().__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.empty(in_feats, out_feats))\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(out_feats)) if bias else None\n",
    "\n",
    "    def forward(self, x, adj):                            \n",
    "        support = x @ self.weight\n",
    "        out = torch.sparse.mm(adj, support)\n",
    "        return out + (self.bias if self.bias is not None else 0.)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super().__init__()\n",
    "        self.gc1 = GCNLayer(nfeat, nhid)\n",
    "        self.gc2 = GCNLayer(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = torch.nn.functional.dropout(x, self.dropout, training=self.training)  # input-dropout\n",
    "        x = torch.nn.functional.relu(self.gc1(x, adj))\n",
    "        x = torch.nn.functional.dropout(x, self.dropout, training=self.training)  # hidden-dropout\n",
    "        x = self.gc2(x, adj)\n",
    "        return torch.nn.functional.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca489b9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "objects = []\n",
    "dataset_name = 'pubmed'\n",
    "for i in range(len(names)):\n",
    "        with open(\"/home/chengtao/Workspace/Tensorflow_GCN/gcn-master/gcn/data/ind.{}.{}\".format(dataset_name, names[i]), 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pickle.load(f, encoding='latin1'))\n",
    "            else:\n",
    "                objects.append(pickle.load(f))\n",
    "                \n",
    "x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "\n",
    "test_idx_reorder = parse_index_file(\"/home/chengtao/Workspace/Tensorflow_GCN/gcn-master/gcn/data/ind.{}.test.index\".format(dataset_name))\n",
    "test_idx_range = np.sort(test_idx_reorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d756642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sp.vstack((allx, tx)).tolil()\n",
    "features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "features = row_normalize(features)\n",
    "adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "adj = normalize_adj(adj)\n",
    "\n",
    "labels = np.vstack((ally, ty))\n",
    "labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "\n",
    "idx_test = test_idx_range.tolist()\n",
    "idx_train = range(len(y))\n",
    "idx_val = range(len(y), len(y)+500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = scipy_to_tensor(features)\n",
    "adj = scipy_to_tensor(adj)\n",
    "idx_train = torch.LongTensor(idx_train)\n",
    "idx_val = torch.LongTensor(idx_val)\n",
    "idx_test = torch.LongTensor(idx_test)\n",
    "check_zero_row_indices(labels, idx_train, idx_val, idx_test)\n",
    "labels = labels_to_tensor(labels)\n",
    "print('features.shape:', features.shape)\n",
    "print('adj.shape:', adj.shape)\n",
    "print('labels.shape:', labels.shape)\n",
    "print('idx_train.shape:', idx_train.shape)\n",
    "print('idx_val.shape:', idx_val.shape)\n",
    "print('idx_test.shape:', idx_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4f8b6",
   "metadata": {},
   "source": [
    "## Check Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_adj = adj.to_dense().numpy()\n",
    "# train_adj = np_adj[idx_train] # (60 x 19717) means 60 nodes, each with 19717 features\n",
    "# val_adj = np_adj[idx_val] # (500 x 19717)\n",
    "# test_adj = np_adj[idx_test] # (1000 x 19717)\n",
    "# train_indices = idx_train.tolist()\n",
    "# val_indices = idx_val.tolist()\n",
    "# test_indices = idx_test.tolist()\n",
    "\n",
    "# count_train_children = defaultdict(list)\n",
    "# train_covered_node_indices = set()\n",
    "\n",
    "# def check_covered_node_indices_and_neighbors(data_adj, data_indices):\n",
    "#     count_neighbors = defaultdict(list)\n",
    "#     covered_node_indices = set()\n",
    "#     for i in range(len(data_adj)):\n",
    "#         curr_node = data_adj[i]\n",
    "#         curr_idx = data_indices[i]\n",
    "#         for j in range(len(curr_node)):\n",
    "#             if curr_node[j] != 0:\n",
    "#                 if i != j:\n",
    "#                     count_neighbors[curr_idx].append(j)\n",
    "#                 covered_node_indices.add(j)\n",
    "#     return covered_node_indices, count_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_covered_nodes, train_neighbors = check_covered_node_indices_and_neighbors(train_adj, train_indices)\n",
    "# val_covered_nodes, val_neighbors = check_covered_node_indices_and_neighbors(val_adj, val_indices)\n",
    "# test_covered_nodes, test_neighbors = check_covered_node_indices_and_neighbors(test_adj, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"total number of train_covered_nodes: {len(train_covered_nodes)}\")\n",
    "# print(f'percentage of train_covered_nodes: {(len(train_covered_nodes) / len(adj)) * 100:.2f}%')\n",
    "# print(f\"total number of val_covered_nodes: {len(val_covered_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# untrained_nodes = set(range(len(adj))) - train_covered_nodes\n",
    "\n",
    "# # count how many untrained nodes appear in validation and testing.\n",
    "# untrained_nodes_in_val = set()\n",
    "# untrained_nodes_in_test = set()\n",
    "# trained_nodes_in_val = set()\n",
    "# trained_nodes_in_test = set()\n",
    "\n",
    "# val_covered_node_list = list(val_covered_nodes)\n",
    "# val_covered_node_list.sort()\n",
    "# test_covered_node_list = list(test_covered_nodes)\n",
    "# test_covered_node_list.sort()\n",
    "\n",
    "# for i in range(len(val_covered_node_list)):\n",
    "#     if val_covered_node_list[i] in untrained_nodes:\n",
    "#         untrained_nodes_in_val.add(val_covered_node_list[i])\n",
    "#     else:\n",
    "#         trained_nodes_in_val.add(val_covered_node_list[i])\n",
    "\n",
    "# for i in range(len(test_covered_node_list)):\n",
    "#     if test_covered_node_list[i] in untrained_nodes:\n",
    "#         untrained_nodes_in_test.add(test_covered_node_list[i])\n",
    "#     else:\n",
    "#         trained_nodes_in_test.add(test_covered_node_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184918e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save untrained_nodes to csv\n",
    "# untrained_nodes_df = pd.DataFrame(list(untrained_nodes), columns=['untrained_nodes'])\n",
    "# untrained_nodes_df.to_csv('./data/untrained_nodes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c275b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"validation nodes that overlap with training nodes:\", len(trained_nodes_in_val))\n",
    "# print(\"testing nodes that overlap with training nodes:\", len(trained_nodes_in_test))\n",
    "# print(\"validation nodes that are untrained:\", len(untrained_nodes_in_val))\n",
    "# print(\"testing nodes that are untrained:\", len(untrained_nodes_in_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1583d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_adj = np.sum(train_adj, axis=0)\n",
    "# print('train_adj.shape:', train_adj.shape)\n",
    "\n",
    "# count_zero = 0\n",
    "# count_nonzero = 0\n",
    "# uncovered_idnices = []\n",
    "\n",
    "# for i in range(len(train_adj)):\n",
    "#     if train_adj[i] == 0:\n",
    "#         count_zero += 1\n",
    "#         uncovered_idnices.append(i)\n",
    "#     else:\n",
    "#         count_nonzero += 1\n",
    "# print('count_zero:', count_zero)\n",
    "# print('count_nonzero:', count_nonzero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc952c13",
   "metadata": {},
   "source": [
    "## Run GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48284d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Reproducibility ──────────────────────────────────────────────────────────\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outputs_history = []\n",
    "# weight_history = []\n",
    "\n",
    "\n",
    "def train(epoch, model, optimizer, log_freq=10):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(features, adj) # forward pass\n",
    "\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train]) # calculate loss 140\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "    \n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "\n",
    "    val_output = output[idx_val].detach().cpu().numpy()\n",
    "    val_outputs_history.append(val_output)\n",
    "\n",
    "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "    if (epoch + 1) % log_freq == 0:\n",
    "        print('Epoch: {:04d}'.format(epoch+1),\n",
    "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "    # return loss_train, acc_train, loss_val, acc_val\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "    # return acc_test, loss_test\n",
    "\n",
    "model = GCN(nfeat=features.shape[1],\n",
    "            nhid=16,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=0.5)\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "device = torch.device('cuda' if True and torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device)\n",
    "labels = labels.to(device)\n",
    "idx_train = idx_train.to(device)\n",
    "idx_val = idx_val.to(device)\n",
    "idx_test = idx_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(nfeat=features.shape[1],\n",
    "            nhid=16,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=0.5)\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb678641",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if True and torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device)\n",
    "labels = labels.to(device)\n",
    "idx_train = idx_train.to(device)\n",
    "idx_val = idx_val.to(device)\n",
    "idx_test = idx_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549cf2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    train(epoch, model, optimizer, log_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520dce39",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd77fd",
   "metadata": {},
   "source": [
    "## NEW GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef5d6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GCN(torch.nn.Module):\n",
    "#     def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "#         super().__init__()\n",
    "#         self.gc1 = GCNLayer(nfeat, nhid)\n",
    "#         self.gc2 = GCNLayer(nhid, nclass)\n",
    "#         self.dropout = dropout\n",
    "\n",
    "#     def forward(self, x, adj):\n",
    "#         x = torch.nn.functional.dropout(x, self.dropout, training=self.training)  # input-dropout\n",
    "#         x = torch.nn.functional.relu(self.gc1(x, adj))\n",
    "#         x = torch.nn.functional.dropout(x, self.dropout, training=self.training)  # hidden-dropout\n",
    "#         x = self.gc2(x, adj)\n",
    "#         return torch.nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "class NewGCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout, input_shape=None, node_masked=None):\n",
    "        super(NewGCN, self).__init__()\n",
    "        self.gc1 = GCNLayer(nfeat, nhid)\n",
    "        self.gc2 = GCNLayer(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "        self.node_masked = node_masked  # list of indices for masked nodes\n",
    "        \n",
    "        total_nodes = input_shape[0]\n",
    "        feature_dim = input_shape[1]\n",
    "\n",
    "        # Compute unmasked indices: nodes not in node_masked.\n",
    "        self.unmasked_indices = [i for i in range(total_nodes) if (node_masked is None or i not in node_masked)]\n",
    "        \n",
    "        if node_masked is not None:\n",
    "            # Create trainable weights only for the unmasked nodes.\n",
    "            init_train_weights = torch.empty(len(self.unmasked_indices), feature_dim)\n",
    "            nn.init.xavier_uniform_(init_train_weights)\n",
    "            self.node_train_weights = nn.Parameter(self.min_max_normalize(init_train_weights), requires_grad=True)\n",
    "            # init_train_weights = torch.ones(len(self.unmasked_indices), feature_dim)\n",
    "            # self.node_train_weights = nn.Parameter(init_train_weights, requires_grad=True)\n",
    "            \n",
    "            # Initialize weights for masked nodes to zero.\n",
    "            init_node_masked_weights = torch.ones(len(node_masked), feature_dim)\n",
    "            self.node_masked_weights = nn.Parameter(init_node_masked_weights, requires_grad=False)\n",
    "        else:\n",
    "            self.node_weights = nn.Parameter(torch.empty(input_shape), requires_grad=True)\n",
    "            nn.init.xavier_uniform_(self.node_weights)\n",
    "\n",
    "    def min_max_normalize(self, x):\n",
    "        x_min = torch.min(x)\n",
    "        x_max = torch.max(x)\n",
    "        return (x - x_min) / (x_max - x_min + 1e-8)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        if self.node_masked is not None:\n",
    "            # reconstruct full [num_nodes, feature_dim] weight matrix\n",
    "            full_w = torch.zeros_like(x, device=x.device)\n",
    "            um_idx = torch.tensor(self.unmasked_indices, device=x.device)\n",
    "            index   = um_idx.unsqueeze(1).expand(-1, x.size(1)) \n",
    "            full_w  = full_w.scatter(0, index, self.node_train_weights)\n",
    "            full_w[self.node_masked] = self.node_masked_weights   \n",
    "        else:\n",
    "            full_w = self.node_train_weights\n",
    "\n",
    "        # scale each node’s feature‐vector\n",
    "        x = x * full_w\n",
    "        x = torch.nn.functional.dropout(x, self.dropout, training=self.training)\n",
    "        x = torch.nn.functional.relu(self.gc1(x, adj))\n",
    "        x = torch.nn.functional.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return torch.nn.functional.log_softmax(x, dim=1)\n",
    "    \n",
    "    #     def forward(self, x, adj):\n",
    "#         x = torch.nn.functional.dropout(x, self.dropout, training=self.training)  # input-dropout\n",
    "#         x = torch.nn.functional.relu(self.gc1(x, adj))\n",
    "#         x = torch.nn.functional.dropout(x, self.dropout, training=self.training)  # hidden-dropout\n",
    "#         x = self.gc2(x, adj)\n",
    "#         return torch.nn.functional.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ca0ed",
   "metadata": {},
   "source": [
    "## Environment Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87936502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "features = features.to(device)\n",
    "adj      = adj.to(device)\n",
    "labels   = labels.to(device)\n",
    "idx_train = idx_train.to(device)\n",
    "idx_val  = idx_val.to(device)\n",
    "idx_test = idx_test.to(device)\n",
    "\n",
    "train_uncovered_node_list = pd.read_csv('./data/train_uncovered_node_list.csv')\n",
    "node_masked = train_uncovered_node_list['untrained_nodes'].tolist()\n",
    "\n",
    "\n",
    "if not os.path.exists('./saved_weights'):\n",
    "    os.mkdir('./saved_weights')\n",
    "\n",
    "phase_one_save_dir = './saved_weights/phase_one'\n",
    "if not os.path.exists(phase_one_save_dir):\n",
    "    os.mkdir(phase_one_save_dir)\n",
    "\n",
    "phase_two_save_dir = './saved_weights/phase_two'\n",
    "if not os.path.exists(phase_two_save_dir):\n",
    "    os.mkdir(phase_two_save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18079ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    # print(\"Test set results:\",\n",
    "    #       \"loss= {:.4f}\".format(loss_test.item()),\n",
    "    #       \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "    return acc_test, loss_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424137d7",
   "metadata": {},
   "source": [
    "## Phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af47d898",
   "metadata": {},
   "source": [
    "### Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45d26338",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHASE_ONE_COUNT    = 3\n",
    "PHASE_ONE_ACTIVE_EARLY_STOPPING = True\n",
    "\n",
    "epochs             = 200\n",
    "node_weights_lr    = 0.0\n",
    "node_weights_decay = 0.0\n",
    "gc_layers_lr       = 1e-2\n",
    "gc_layers_decay    = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5053dc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 62\n",
      "Run 1/3 - Test Accuracy: 0.7740, Test Loss: 0.6020\n",
      "Early stopping triggered at epoch 56\n",
      "Run 2/3 - Test Accuracy: 0.7610, Test Loss: 0.5960\n",
      "Early stopping triggered at epoch 59\n",
      "Run 3/3 - Test Accuracy: 0.7660, Test Loss: 0.5809\n",
      "Mean Test Accuracy: 0.7670 ± 0.0054\n",
      "Mean Test Loss: 0.5930 ± 0.0089\n"
     ]
    }
   ],
   "source": [
    "phase1_test_acc_list = []\n",
    "phase1_test_loss_list = []\n",
    "\n",
    "for run in range(PHASE_ONE_COUNT):\n",
    "    model = NewGCN(\n",
    "        nfeat   = features.shape[1],\n",
    "        nhid    = 64,\n",
    "        nclass  = labels.max().item() + 1,\n",
    "        dropout = 0.4,\n",
    "        input_shape = features.shape,\n",
    "        node_masked = node_masked\n",
    "    )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    param_groups = [\n",
    "        {\n",
    "            'params': [model.node_train_weights],\n",
    "            'lr': node_weights_lr,\n",
    "            'weight_decay': node_weights_decay\n",
    "        },\n",
    "        {\n",
    "            'params': [\n",
    "                p for n,p in model.named_parameters()\n",
    "                if n != 'node_train_weights'\n",
    "            ],\n",
    "            'lr': gc_layers_lr,\n",
    "            'weight_decay': gc_layers_decay\n",
    "        }\n",
    "    ]\n",
    "    optimizer = optim.Adam(param_groups)\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=10, \n",
    "        verbose=False, \n",
    "        save_path=f\"{phase_one_save_dir}/best_model_phase1_({run})run.pth\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ---- train ----\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features, adj)\n",
    "        loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ---- val ----\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out_val = model(features, adj)\n",
    "            acc_val = accuracy(out_val[idx_val], labels[idx_val])\n",
    "            loss_val = F.nll_loss(out_val[idx_val], labels[idx_val])\n",
    "        \n",
    "        if PHASE_ONE_ACTIVE_EARLY_STOPPING:\n",
    "            early_stopping(loss_val, model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Save the model of last epoch\n",
    "    if not PHASE_ONE_ACTIVE_EARLY_STOPPING:\n",
    "        torch.save(model.state_dict(), f\"{phase_one_save_dir}/last_model_phase1_({run})run.pth\")\n",
    "\n",
    "    # ---- test ----\n",
    "    acc_test, loss_test = test(model)\n",
    "    phase1_test_acc_list.append(acc_test.item())\n",
    "    phase1_test_loss_list.append(loss_test.item())\n",
    "    print(f\"Run {run+1}/{PHASE_ONE_COUNT} - Test Accuracy: {acc_test.item():.4f}, Test Loss: {loss_test.item():.4f}\")\n",
    "\n",
    "\n",
    "std_acc = np.std(phase1_test_acc_list)\n",
    "mean_acc = np.mean(phase1_test_acc_list)\n",
    "std_loss = np.std(phase1_test_loss_list)\n",
    "mean_loss = np.mean(phase1_test_loss_list)\n",
    "print(f\"Mean Test Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "print(f\"Mean Test Loss: {mean_loss:.4f} ± {std_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591021e6",
   "metadata": {},
   "source": [
    "### Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12eced1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_WEIGHT_DROP_RATE = 0.0\n",
    "INIT_VALUE_FOR_ZERO_WEIGHT = 1e-12\n",
    "PHASE_TWO_COUNT = 3\n",
    "PHASE_TWO_ACTIVE_EARLY_STOPPING = True\n",
    "\n",
    "epochs = 200\n",
    "node_weights_lr     = 0.001\n",
    "node_weights_decay  = 0.0\n",
    "gc_layers_lr        = 0.0\n",
    "gc_layers_lr_decay  = 0.0\n",
    "phase1_saved_model_name = 'best_model_phase1' if PHASE_ONE_ACTIVE_EARLY_STOPPING else 'last_model_phase1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d526067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_686448/1603198234.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"{phase_one_save_dir}/{phase1_saved_model_name}_({run})run.pth\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 11\n",
      "Run 1/3 - Test Accuracy: 0.7620, Test Loss: 0.5901\n",
      "Early stopping triggered at epoch 11\n",
      "Run 2/3 - Test Accuracy: 0.7450, Test Loss: 0.5926\n",
      "Early stopping triggered at epoch 11\n",
      "Run 3/3 - Test Accuracy: 0.7580, Test Loss: 0.5777\n",
      "Mean Test Accuracy: 0.7550 ± 0.0073\n",
      "Mean Test Loss: 0.5868 ± 0.0065\n"
     ]
    }
   ],
   "source": [
    "phase2_test_acc_list = []\n",
    "phase2_test_loss_list = []\n",
    "\n",
    "# replace zero value in the features\n",
    "features = torch.where(features == 0, torch.tensor(INIT_VALUE_FOR_ZERO_WEIGHT, device=features.device), features)\n",
    "\n",
    "for run in range(PHASE_TWO_COUNT):\n",
    "\n",
    "    # ------ Set up model ------\n",
    "    # 1. instantiate the model\n",
    "    model = NewGCN(\n",
    "        nfeat   = features.shape[1],\n",
    "        nhid    = 64,\n",
    "        nclass  = labels.max().item() + 1,\n",
    "        dropout = NODE_WEIGHT_DROP_RATE, # set dropout rate to 0.0\n",
    "        input_shape = features.shape,\n",
    "        node_masked = node_masked\n",
    "    )\n",
    "\n",
    "    # 2. load the best model from phase 1\n",
    "    state_dict = torch.load(f\"{phase_one_save_dir}/{phase1_saved_model_name}_({run})run.pth\")\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # 4. set model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 5. set optimizer\n",
    "    param_groups = [\n",
    "        {\n",
    "            'params': [model.node_train_weights],\n",
    "            'lr': node_weights_lr,\n",
    "            'weight_decay': node_weights_decay\n",
    "        },\n",
    "        {\n",
    "            'params': [\n",
    "                p for n,p in model.named_parameters()\n",
    "                if n != 'node_train_weights'\n",
    "            ],\n",
    "            'lr': gc_layers_lr,\n",
    "            'weight_decay': gc_layers_decay\n",
    "        }\n",
    "    ]\n",
    "    optimizer = optim.Adam(param_groups)\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=10, \n",
    "        verbose=False, \n",
    "        save_path=f\"{phase_two_save_dir}/best_model_phase1_({run})run.pth\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(features, adj)\n",
    "        loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "        acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "        \n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out_val = model(features, adj)\n",
    "            acc_val = accuracy(out_val[idx_val], labels[idx_val])\n",
    "            loss_val = F.nll_loss(out_val[idx_val], labels[idx_val])\n",
    "\n",
    "        if PHASE_TWO_ACTIVE_EARLY_STOPPING:\n",
    "            early_stopping(loss_val, model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Save the model of last epoch\n",
    "    if not PHASE_TWO_ACTIVE_EARLY_STOPPING:\n",
    "        torch.save(model.state_dict(), f\"{phase_two_save_dir}/last_model_phase2_({run})run.pth\")\n",
    "\n",
    "    # ---- test ----\n",
    "    acc_test, loss_test = test(model)\n",
    "    phase2_test_acc_list.append(acc_test.item())\n",
    "    phase2_test_loss_list.append(loss_test.item())\n",
    "    print(f\"Run {run+1}/{PHASE_ONE_COUNT} - Test Accuracy: {acc_test.item():.4f}, Test Loss: {loss_test.item():.4f}\")\n",
    "\n",
    "\n",
    "std_acc = np.std(phase2_test_acc_list)\n",
    "mean_acc = np.mean(phase2_test_acc_list)\n",
    "std_loss = np.std(phase2_test_loss_list)\n",
    "mean_loss = np.mean(phase2_test_loss_list)\n",
    "print(f\"Mean Test Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "print(f\"Mean Test Loss: {mean_loss:.4f} ± {std_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237ec1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
